{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200e3bab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 7\n",
    "## MATH 189 • Data Analysis & Inference • Wi 2024\n",
    "### Siddharth Vishwanath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700143e-29e1-4307-9662-02a03e22ef20",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "$\\forcecommand{\\pvalue}{p\\text{-value}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\newcommand{\\E}{\\mathbb{E}}$\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96abc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Agenda\n",
    "---\n",
    "\n",
    "#### Regression Analysis\n",
    "1. Diagnostics\n",
    "    * Residual diagnostics\n",
    "    * Outliers and influential points\n",
    "    * Transformations\n",
    "\n",
    "2. Hypothesis Testing\n",
    "    * Testing the coefficients\n",
    "    * Testing the model itself\n",
    "    * Testing effects of multiple variables\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ea4ab",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f314af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Optional \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41157f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85f8ca4",
   "metadata": {},
   "source": [
    "## The picture so far ...\n",
    "\n",
    "\n",
    "### The data\n",
    "\n",
    "* $p$ variables $x_1, x_2, \\dots, x_p$ and \n",
    "* a response variable $y$, and \n",
    "* a dataset of $n$ observations\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x_{11} & x_{12} & \\dots & x_{1p} & y_1 \\\\\n",
    "x_{21} & x_{22} & \\dots & x_{2p} & y_2 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & \\dots & x_{np} & y_n \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "where $x_{ij}$ is the value of:\n",
    "\n",
    "* the $i$-th observation of\n",
    "* the $j$-th independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62d02c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### The regression model\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\iid (0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Equivalently, in matrix notation:\n",
    "\n",
    "$$\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}\n",
    "}_{\\yv}\n",
    "= \n",
    "\\underbrace{\n",
    "    \\begin{pmatrix}\n",
    "    1 & x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
    "    1 & x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    1 & x_{n1} & x_{n2} & \\dots & x_{np} \\\\\n",
    "    \\end{pmatrix}\n",
    "}_{\\Xv}\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_p\n",
    "\\end{pmatrix}\n",
    "}_{\\betav}\n",
    "+\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\epsilon_n\n",
    "\\end{pmatrix}\n",
    "}_{\\epsilonv}\n",
    "$$\n",
    "i.e., \n",
    "$$\n",
    "\\yv = \\Xv \\betav + \\epsilonv\n",
    "$$\n",
    "\n",
    "where\n",
    "* $\\Xv$ is called the design matrix / the covariate matrix / the feature matrix\n",
    "* $\\betav$ is the vector of coefficients\n",
    "* $\\epsilonv$ is the vector of errors\n",
    "* $\\yv$ is the vector of responses\n",
    "\n",
    "The assumption that $\\epsilon_i \\iid (0, \\sigma^2)$ is equivalent to the assumption that $\\epsilonv$ follows a **multivariate Normal distribution**, i.e.,\n",
    "$\\epsilonv \\sim N\\Big(\\zerov_d, \\sigma^2 \\Iv_{d \\times d}\\Big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37c7460",
   "metadata": {},
   "source": [
    "---\n",
    "### The estimates\n",
    "\n",
    "* The estimate for the coefficients is given by $\\hat\\betav$:\n",
    "\n",
    "$$\n",
    "\\hat\\betav = (\\Xv^T \\Xv)^{-1} \\Xv^T \\yv\n",
    "$$\n",
    "\n",
    "* The fitted values are given by $\\hat\\yv$:\n",
    "\n",
    "$$\n",
    "\\hat\\yv = \\Xv \\hat\\betav\n",
    "$$\n",
    "\n",
    "* The residuals are given by $\\hat\\epsilonv$:\n",
    "\n",
    "$$\n",
    "\\hat\\epsilonv = \\yv - \\hat\\yv\n",
    "$$\n",
    "\n",
    "* The estimate for $\\sigma^2$ is given by:\n",
    "\n",
    "$$\n",
    "\\hat\\sigma^2 = \\frac{1}{n - p - 1} \\sum_{i=1}^n \\hat\\epsilon_i^2\n",
    "$$\n",
    "\n",
    "let's do a quick check comparing brute-force in `numpy`  with the output from `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5177da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2, x3 = (np.random.rand(100) for _ in range(3))\n",
    "y = 10 + 2 * x1 + 3 * x2 + 4 * x3 + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34de52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first principles\n",
    "X = np.column_stack((x1, x2, x3))\n",
    "b = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "y_hat = X @ b\n",
    "residuals = y - y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c192c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statsmodels\n",
    "fit = sm.OLS(y, X).fit()\n",
    "b_sm = fit.params\n",
    "y_hat_sm = fit.fittedvalues\n",
    "residuals_sm = fit.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29462e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(b_sm, b * (1 + 1e-10))\n",
    "np.testing.assert_allclose(y_hat_sm, y_hat)\n",
    "np.testing.assert_allclose(residuals_sm, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbeed60",
   "metadata": {},
   "source": [
    "---\n",
    "### The interpretation\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y &\\sim N\\Big( \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p, \\sigma^2\\Big) \\\\ \\\\\n",
    "\\E(y | x_1, x_2, \\dots x_p) &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\\\ \\\\\n",
    "\\frac{\\partial}{\\partial x_j} \\E(y | x_1, x_2, \\dots x_p) &= \\beta_j\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$\\beta_j$ is the expected change in the response $y$ for an infinitesimal change in the $j$-th variable $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34cba89",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e8140",
   "metadata": {},
   "source": [
    "> What happens if $x_j$ is discrete? e.g., $x_j \\in \\{0, 1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f326e81",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8893180",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\E(y | x_1 \\dots x_p \\text{ and } x_j = 1) &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_j + \\dots + \\beta_p x_p\\\\ \\\\\n",
    "\\E(y | x_1 \\dots x_p \\text{ and } x_j = 0) &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + 0 + \\dots + \\beta_p x_p\\\\ \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "So\n",
    "$$\n",
    "\\beta_j = \\E(y | x_1 \\dots x_p \\text{ and } x_j = 1) - \\E(y | x_1 \\dots x_p \\text{ and } x_j = 0)\n",
    "$$\n",
    "\n",
    "\n",
    "> For a discrete covariate $x_j$, $\\beta_j$ is the expected change in the response $y$ for a unit change in $x_j$.\n",
    "\n",
    "\n",
    "Prooceed with caution:\n",
    "\n",
    "* For an ordinal covariate $x_j$, a ``unit change`` is not the same across the different levels\n",
    "    * e.g., if $x_j = 0, 1, 2$ corresponds to $x_j = \\text{low}, \\text{medium}, \\text{high}$, then the change from low to medium is not necessarily the same as the change from medium to high.\n",
    "* For a categorical covariate $x_j$, a ``unit change`` may not even have a meaningful interpretation\n",
    "    * e.g., if $x_j = 0, 1$ corresponds to $x_j = \\text{red}, \\text{blue}$, then the change from $x_j = 0$ to $x_j = 1$ needs to be interpreted with caution.\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "Where it is meaningful:\n",
    "\n",
    "* $x_j = 1$ for `females` and $x_j = 0$ for `males` then $\\beta_j$ measures the effect of `sex` on the response variable\n",
    "* $x_j = 1$ for `smokers` and $x_j = 0$ for `non-smokers` then $\\beta_j$ measures the impact of `smoking` on the response variable\n",
    "\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "Be careful:\n",
    "\n",
    "* $x_j = 1$ for `smokers` and $x_j = 0$ for `non-smokers` then $\\beta_j$ measures the expected difference in $y$ for `smokers` - `non-smokers`\n",
    "* $x_j = 1$ for `non-smokers` and $x_j = 0$ for `smokers` then $\\beta_j$ measures the expected difference in $y$ for `non-smokers` - `smokers`\n",
    "\n",
    "> This is known as the **reference level** problem and is a common source of confusion in interpreting the coefficients of a regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6fe8e",
   "metadata": {},
   "source": [
    "[Gender wage gap statistics](https://www.pewresearch.org/social-trends/2023/03/01/the-enduring-grip-of-the-gender-pay-gap/#:~:text=The%20gender%20pay%20gap%20%E2%80%93%20the,every%20dollar%20earned%20by%20men.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c0f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing reference level in statsmodels\n",
    "np.random.seed(0)\n",
    "sex    = pd.Categorical(np.random.choice(['female', 'male', 'c'], size=200))\n",
    "income = [(s == 'male') * 10000 +stats.norm(50000, 10000).rvs() for s in sex]\n",
    "df = pd.DataFrame({'sex': sex, 'income': income})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70877ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing reference level in statsmodels\n",
    "df.sex = pd.Categorical(df.sex, ['female', 'male'])\n",
    "b1 = smf.ols('income ~ sex', df).fit().params\n",
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4487930-6d0a-46a8-ada2-4c3dd75bdaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_gap_1 = (b1[0]) / (b1[0] + b1[1])\n",
    "gender_gap_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00de24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex = pd.Categorical(df.sex, ['male', 'female'])\n",
    "b2 = smf.ols('income ~ sex', df).fit().params\n",
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d94bf9-935b-4104-8c19-823fabd5ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_gap_2 = (b2[0] + b2[1]) / b2[0]\n",
    "gender_gap_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6325074c",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd30df6",
   "metadata": {},
   "source": [
    "---\n",
    "## The assumptions\n",
    "\n",
    "* (Independence)$ \\epsilon_1, \\epsilon_2, \\dots, \\epsilon_n$ are independent\n",
    "* (Identical / homoscedasticity) The errors have constant variance, i.e., $\\text{Var}(\\epsilon_i) = \\sigma^2$ for all $i$\n",
    "* (Normally distributed) $\\epsilon_i \\sim N(0, \\sigma^2)$\n",
    "* (Linearity) The relationship between the independent variables and the response is linear\n",
    "\n",
    "> **ANY INFERENCE FROM THE REGRESSION MODEL IS VALID ONLY IF THE ASSUMPTIONS ARE MET**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca719f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br></br><br></br><br></br>\n",
    "<br></br><br></br><br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666752b4",
   "metadata": {},
   "source": [
    "# §1. Diagnostics\n",
    "\n",
    "**The residuals are the key tool used to diagnose the assumptions of a regression model.**\n",
    "\n",
    "Some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3079ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(errors):\n",
    "    n = len(errors)\n",
    "    x1 = np.linspace(0, 1, n)\n",
    "    x2 = np.random.rand(n)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'x1': x1, \n",
    "        'x2': x2, \n",
    "        'y': 2 + 3*x1 + 4*x2 + errors\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874eb747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression(data, fit, residuals=True):\n",
    "    b = fit.params\n",
    "    b0, b1, b2 = *b, *np.zeros(3 - len(b))\n",
    "    y, x1, x2 = data.y, data.x1, data.x2\n",
    "    fig = px.scatter_3d(x=x1, y=x2, z=y)\n",
    "    fig.update_layout(\n",
    "        scene = dict(\n",
    "            xaxis_title='X1',\n",
    "            yaxis_title='X2',\n",
    "            zaxis_title='Y'),\n",
    "            margin=dict(l=0, r=0, b=0, t=0\n",
    "        )\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    \n",
    "    x1_grid, x2_grid = np.meshgrid(x1, x2)\n",
    "    yhat = b0 + (b1 * x1_grid) + (b2 * x2_grid)\n",
    "    fig.add_trace(\n",
    "        go.Surface(x=x1_grid, y=x2_grid, z=yhat, opacity=0.5,colorscale='Gray')\n",
    "    )\n",
    "    if residuals:\n",
    "        for i in range(len(x1)):\n",
    "            fig.add_trace(\n",
    "                go.Scatter3d(x=[x1[i], x1[i]], y=[x2[i], x2[i]], z=[b0 + b1*x1[i] + b2*x2[i], y[i]], mode='lines', line=dict(color='black', width=2))\n",
    "            )\n",
    "    fig.update_layout(showlegend=False, scene_camera=dict(eye=dict(x=2.0, y=0.5, z=0.1)))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf8b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00475c-2844-4a2b-a13a-4b87590f0fd9",
   "metadata": {},
   "source": [
    "$$\n",
    "x_1, x_2, \\dots, x_n \\to \\frac{x_1 - \\overline x}{\\text{sd}(x)}, \\frac{x_1 - \\overline x}{\\text{sd}(x)}, \\dots, \\frac{x_n - \\overline x}{\\text{sd}(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c03d3b",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>\n",
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9451834f",
   "metadata": {},
   "source": [
    "\n",
    "> ## Checking for Normality of the Residuals\n",
    "\n",
    "1. QQ-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105459dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets simulate 3 datasets with different types of residuals\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 100\n",
    "data = [\n",
    "    make_data( stats.norm(0, 0.5).rvs(n)  ),\n",
    "    make_data( stats.norm(10, 1).rvs(n)  ),\n",
    "    make_data( stats.expon(10).rvs(n)  ),\n",
    "]\n",
    "\n",
    "results = [smf.ols('y ~ x1 + x2', data=df).fit() for df in data]\n",
    "residuals = [standardize(result.resid) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd93814",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(results), figsize=(5 * len(results), 5))\n",
    "for i, resid in enumerate(residuals):\n",
    "    sm.qqplot(resid, ax=axs[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c4fb4",
   "metadata": {},
   "source": [
    "2. Shapiro-Wilk test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca9a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_pvalues = [stats.shapiro(r.resid).pvalue for r in results]\n",
    "shapiro_pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e265ccc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br></br><br></br><br></br>\n",
    "<br></br><br></br><br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e428a1",
   "metadata": {},
   "source": [
    "\n",
    "> ## Checking for Independence of the Residuals\n",
    "\n",
    "1. Scatterplot of the residuals against the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaff2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets simulate 2 datasets with different types of residuals\n",
    "np.random.seed(0)\n",
    "n = 200\n",
    "\n",
    "# Normal independent errors\n",
    "epsilon = stats.norm(0, 0.5).rvs(n)\n",
    "\n",
    "# Autoregressive errors\n",
    "ar_epsilon = np.zeros(n)\n",
    "for i in range(2, n):\n",
    "    ar_epsilon[i] = 0.8 * ar_epsilon[i-1] + 0.2 * ar_epsilon[i-2] + 0.5 * epsilon[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84142461",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    make_data(epsilon), \n",
    "    make_data(ar_epsilon)\n",
    "]\n",
    "results = [smf.ols('y ~ x1 + x2', data=df).fit() for df in data]\n",
    "residuals = [standardize(result.resid) for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c01d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(results), figsize=(len(results) * 5, 5))\n",
    "for i, resid in enumerate(residuals):\n",
    "    ax[i].scatter(range(n), resid)\n",
    "    ax[i].set_xlabel('observation'); ax[i].set_ylabel('standardized residuals'); ax[i].set_title(f'Data {i+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdacc38",
   "metadata": {},
   "source": [
    "2. Scatterplot of the residuals against independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, len(results), figsize=(len(results) * 6, 7))\n",
    "\n",
    "for i, (resid, df) in enumerate(zip(residuals, data)):\n",
    "    ax[0, i].scatter(df.x1, resid)\n",
    "    ax[0, i].set_title('Residuals vs x1')\n",
    "    ax[1, i].scatter(df.x2, resid)\n",
    "    ax[1, i].set_title('Residuals vs x2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518df5c",
   "metadata": {},
   "source": [
    "3. ACF plot of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "fig, ax = plt.subplots(1, len(results), figsize=(len(results) * 5, 5))\n",
    "\n",
    "lags = 20\n",
    "for i, resid in enumerate(residuals):\n",
    "    ax[i].bar(range(lags+1), acf(resid, nlags=lags))\n",
    "    ax[i].set_xlabel('lag'); ax[i].set_ylabel('ACF'); ax[i].set_title(f'Data {i+1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20132947",
   "metadata": {},
   "source": [
    "4. Test for independence using the Durbin-Watson test or the Ljung-Box test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c9900",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "for i, resid in enumerate(residuals):\n",
    "    p_values = list(\n",
    "        acorr_ljungbox(resid, lags=3, return_df=False).lb_pvalue\n",
    "    )\n",
    "    print(f'data: {i+1} \\t p_values for each lag:{p_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da94ca1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<br></br><br></br><br></br>\n",
    "<br></br><br></br><br></br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2808538",
   "metadata": {},
   "source": [
    "\n",
    "> ## Checking for Heteroscedasticity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets simulate 3 datasets with different types of residuals\n",
    "n = 500\n",
    "\n",
    "# Normal iid errors\n",
    "epsilon = stats.norm(0, 0.5).rvs(n)\n",
    "\n",
    "# Non-homogeneous errors\n",
    "up_epsilon = epsilon * np.array([0.1*i for i in range(n)])\n",
    "dn_epsilon = epsilon * np.array([0.1*(n-i) for i in range(n)])\n",
    "\n",
    "data = [\n",
    "    make_data(epsilon),\n",
    "    make_data(up_epsilon),\n",
    "    make_data(dn_epsilon),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff90779",
   "metadata": {},
   "source": [
    "We'll add another dataset which has a non-linear relationship between the predictors and the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e8c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = data[0].x1, data[0].x2\n",
    "y = ((1 + 2*x1 + 3*(x1 ** x2)) + epsilon)**3\n",
    "\n",
    "data.append(pd.DataFrame({'x1': x1, 'x2': x2, 'y': y}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d24688",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [smf.ols('y ~ x1 + x2', data=df).fit() for df in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd33de7",
   "metadata": {},
   "source": [
    "1. Plot the residuals against the observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1fd5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(results), figsize=(len(results) * 5, 5))\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    ax[i].scatter(range(n), standardize(res.resid))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3643bfed",
   "metadata": {},
   "source": [
    "1. Plot the residuals against the fitted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, len(results), figsize=(len(results) * 5, 5))\n",
    "\n",
    "for i, res in enumerate(results):\n",
    "    ax[i].scatter(res.fittedvalues, standardize(res.resid))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f825746-c211-4788-835a-916b7cae2dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression(data[2], results[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa345dd",
   "metadata": {},
   "source": [
    "3. Performing the Breusch-Pagan test or the White test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e1d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48100a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# het_white?\n",
    "# het_breuschpagan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41401e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(results):\n",
    "    p_values = het_white(res.resid, res.model.exog)[3]\n",
    "    print(f'model: {i} \\t p_value: {p_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bc54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in enumerate(results):\n",
    "    p_values = het_breuschpagan(res.resid, res.model.exog)[3]\n",
    "    print(f'model: {i} \\t p_values: {p_values}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1920fa",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc2ea0",
   "metadata": {},
   "source": [
    "## Outliers and influential points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf9bae",
   "metadata": {},
   "source": [
    "* Outliers are observations with large residuals\n",
    "* Influential points are observations that have a large effect on the regression model. \n",
    "\n",
    "> Surprisingly, they are not the same thing!!\n",
    "\n",
    "* $x_i$ is an outlier if $e_i$ is large\n",
    "* $x_i$ is influential if $|\\hat\\beta_{(-i)} - \\hat\\beta|$ is large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8834c3",
   "metadata": {},
   "source": [
    "The most famous example comes from [Anscombe's quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877d54e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10, 8, 13, 9, 11, 14, 6, 4, 12, 7, 5]\n",
    "x4 = [8.001, 8.002, 8.003, 8.004, 7.999, 7.998, 7.997, 19, 8.000, 8.005, 7.996]\n",
    "\n",
    "ys = [\n",
    "    [8.04, 6.95, 7.58, 8.81, 8.33, 9.96, 7.24, 4.26, 10.84, 4.82, 5.68], \n",
    "    [9.14, 8.14, 8.74, 8.77, 9.26, 8.10, 6.13, 3.10, 9.13, 7.26, 4.74], \n",
    "    [7.46, 6.77, 12.74, 7.11, 7.81, 8.84, 6.08, 5.39, 8.15, 6.42, 5.73], \n",
    "    [6.58, 5.76, 7.71, 8.84, 8.47, 7.04, 5.25, 12.50, 5.56, 7.91, 6.89]\n",
    "]\n",
    "\n",
    "data = [pd.DataFrame({'x': x, 'y': y}) for y in ys]\n",
    "data[4-1].x = x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609715cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(7, 7))\n",
    "\n",
    "for i, (df, ax) in enumerate(zip(data, axs.ravel())):\n",
    "    ax.scatter(df.x, df.y)\n",
    "    ax.set_title(f'Dataset {i+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0838f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [smf.ols('y ~ x', data=df).fit() for df in data]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "for i, (df, ax) in enumerate(zip(data, axs.ravel())):\n",
    "    ax.scatter(df.x, df.y)\n",
    "    x = np.linspace(df.x.min(), df.x.max(), 100)\n",
    "    y = results[i].params['Intercept'] + results[i].params['x'] * x\n",
    "    ax.plot(x, y, color='red')\n",
    "    ax.set_title(f'y = {results[i].params[\"Intercept\"]:.2f} + {results[i].params[\"x\"]:.2f}x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c952af",
   "metadata": {},
   "source": [
    "| Anscombe's Quartet | $\\phantom{1}$  |\n",
    "|---|---|\n",
    "Satisfies assumptions | Nonlinear data |\n",
    "Outlier | Influential point |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22bb40b",
   "metadata": {},
   "source": [
    "The influence of a point is usually measured using Cook's distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get influence of points in the dataset\n",
    "results[3].get_influence().summary_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05420689",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'dfb_x'\n",
    "y = results[3].get_influence().summary_frame()[metric]\n",
    "x = range(len(y))\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('observation'); plt.ylabel(f'{metric}'); plt.title(f'{metric} for each observation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d86ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[3].get_influence().plot_influence();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13ea29",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 7\n",
    "plt.scatter(data[3].x, data[3].y)\n",
    "plt.scatter(data[3].x[i], data[3].y[i], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4ef938",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[2].get_influence().plot_influence();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e20a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "plt.scatter(data[2].x, data[2].y)\n",
    "plt.scatter(data[2].x[i], data[2].y[i], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df75d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with and without the influential point\n",
    "df = data[2]\n",
    "i = 2\n",
    "df_drop = df.drop(i, axis=0)\n",
    "\n",
    "inf_data = [df, df_drop]\n",
    "models = [smf.ols('y ~ x', data=df).fit() for df in inf_data]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "for i, (df, model, ax) in enumerate(zip(inf_data, models, ax)):\n",
    "    ax.scatter(df.x, df.y)\n",
    "    x = np.linspace(df.x.min(), df.x.max(), 100)\n",
    "    ax.set_ylim(3, 15)\n",
    "    y = model.params['Intercept'] + model.params['x'] * x\n",
    "    ax.plot(x, y, color='red')\n",
    "    ax.set_title(f'y = {model.params[\"Intercept\"]:.2f} + {model.params[\"x\"]:.2f}x')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e7bd6",
   "metadata": {},
   "source": [
    "<br></br><br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02898c9f",
   "metadata": {},
   "source": [
    "## §2. Hypothesis Testing with Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d3aab1",
   "metadata": {},
   "source": [
    "### §2.1 Anatomy of a regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b68774",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_data(stats.norm(0, 3).rvs(50))\n",
    "fit = smf.ols('y ~ x1 + x2', data=df).fit()\n",
    "fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac997ac1",
   "metadata": {},
   "source": [
    "#### § 2.1.2 - Coefficient Summaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61669825",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f992a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = fit.params\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219253f6",
   "metadata": {},
   "source": [
    "The $p$-values for the coefficients are used to test the null hypothesis that the coefficient is zero, i.e., \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: \\beta_j = 0 \\\\\n",
    "H_a &: \\beta_j \\neq 0\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c068e",
   "metadata": {},
   "source": [
    "At level $\\alpha$, if the $p$-value for the $j$-th coefficient is less than $\\alpha$, then we reject the null hypothesis that the $j$-th coefficient is zero, i.e., \n",
    "\n",
    "> If $p_j < \\alpha$ then the $j$-th variable $x_j$ has a meaningful effect on the response variable $y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8dfd3",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "> How are the p-values computed? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a60b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-distribution\n",
    "\n",
    "coefficient = 'Intercept'\n",
    "t = fit.params[coefficient] / fit.bse[coefficient]\n",
    "df = fit.df_resid\n",
    "\n",
    "t_distribution = stats.t(df)\n",
    "t_p_value = 2 * (1 - t_distribution.cdf(np.abs(t)))\n",
    "t_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9faa9d2",
   "metadata": {},
   "source": [
    "$$\n",
    "\\E(y | x_1, x_2) = 2.3 + 2.9 x_1 + 2.8 x_2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df7403",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13046b5e",
   "metadata": {},
   "source": [
    "#### §2.1.1 Model Fit Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997421de",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09da0a",
   "metadata": {},
   "source": [
    "> ### Sum of squares\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{SS}_{Res} &= \\sum_{i=1}^n (\\hat y_i - y_i)^2 =  \\sum_{i=1}^n \\hat\\epsilon_i^2 \\\\ \\\\\n",
    "\\text{SS}_{Reg} &= \\sum_{i=1}^n (\\hat y_i - \\overline y)^2 \\\\ \\\\\n",
    "\\text{SS}_{Tot} &= \\sum_{i=1}^n (y_i - \\overline y)^2\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "By the Pythagorean theorem, \n",
    "$$\n",
    "\\begin{aligned}\n",
    "&(y_i - \\overline y)^2 &&= (\\hat y_i - \\overline y)^2 &&+ (\\hat y_i - y_i)^2 \\\\\n",
    "\\Longrightarrow &\\quad \\text{SS}_{Tot} &&= \\text{SS}_{Reg} &&+ \\text{SS}_{Res}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e00b223",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_res = np.sum((fit.resid ** 2))\n",
    "ss_reg = np.sum((fit.fittedvalues - df.y.mean()) ** 2)\n",
    "ss_tot = np.sum((df.y - df.y.mean()) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ebbba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(ss_tot, ss_res + ss_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a0826",
   "metadata": {},
   "source": [
    "> ### R-squared\n",
    "\n",
    "$$\n",
    "R^2 = \\frac{\\text{SS}_{Reg}}{\\text{SS}_{Tot}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0244dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squared = ss_reg / ss_tot\n",
    "print(f'R-squared: {r_squared:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5259c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression(df, smf.ols('y ~ 1', data=df).fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_regression(df, smf.ols('y ~ x1 + x2', data=df).fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfde378",
   "metadata": {},
   "source": [
    "> #### F-statistic\n",
    "\n",
    "The $F$-statistic is measure of how well the model explains the variance in the data. It is given by:\n",
    "\n",
    "$$\n",
    "\\hat F = \\frac{\\text{SS}_{Reg} / \\text{df}_{Reg}}{\\text{SS}_{Res} / \\text{df}_{Res}}\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{df}_{Reg} &= p\\\\\n",
    "\\text{df}_{Res} &= n - p - 1\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# degrees of freedom\n",
    "df_reg, df_res = 2, df.shape[0] - 3\n",
    "\n",
    "f = (ss_reg / df_reg) / (ss_res / df_res)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0699a71",
   "metadata": {},
   "source": [
    "The $F$-statistic is used to test the null hypothesis that the model is no better than the null model, i.e., the model with no predictors.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: \\beta_1 = \\beta_2 = \\dots = \\beta_p = 0 \\\\\n",
    "H_a &: \\text{At least one } \\beta_j \\neq 0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The $F$ statistic follows a $\\text{F}(\\text{df}_{Reg}, \\text{df}_{Res})$ distribution under the null hypothesis, i.e.,\n",
    "$$\n",
    "\\hat F = \\frac{\\text{SS}_{Reg} / \\text{df}_{Reg}}{\\text{SS}_{Res} / \\text{df}_{Res}} \\sim \\text{F}(\\text{df}_{Reg}, \\text{df}_{Res})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfaa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_distribution = stats.f(df_reg, df_res)\n",
    "F_p_value = 1 - F_distribution.cdf(f)\n",
    "F_p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7cd432",
   "metadata": {},
   "source": [
    "> ### ANOVA: Analysis of Variance\n",
    "\n",
    "ANOVA is a method used to test whether the inclusion of a set of variables in a model significantly improves the model fit (among other things...)\n",
    "\n",
    "The intuition for ANOVA:\n",
    "\n",
    "> Setting: \n",
    "Suppose we have two models:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Small model:} \\quad y_i &= \\beta_0 + \\beta_1 x_1 + \\beta_3 x_3 + \\beta_{p-1}x_{p-1} +  \\epsilon_i \\\\ \\\\\n",
    "\\text{Big model:} \\quad y_i &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 +  \\dots + \\beta_p x_p + \\epsilon_i \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "i.e., \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{Small model:} \\quad (\\beta_0, \\beta_1, \\beta_3, \\beta_{p-1}) \\\\\n",
    "\\text{Big model:} \\quad (\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\dots, \\beta_p) \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "\n",
    "> Objective:\n",
    "\n",
    "We want to assess whether the inclusion of the variables $x_2, x_4 \\dots, x_p$ in big model **significantly improves** the model fit.\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "\n",
    "> Method:\n",
    "\n",
    "* How much excess variance is explained by the inclusion of variables in Big Model?<br><br>\n",
    "    * > Answer: $\\text{SS}_{Reg}(\\text{Small Model}) - \\text{SS}_{Reg}(\\text{Big Model})$\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "* How many degrees of freedom are used up by the inclusion of variables in Big Model?<br><br>\n",
    "    * > Answer: $\\Delta \\text{df} = \\text{df}_{Reg}(\\text{Small Model}) - \\text{df}_{Reg}(\\text{Big Model})$\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "* How much residual variance is left after the inclusion of variables in Big Model?<br><br>\n",
    "    * > Answer: $\\text{SS}_{Res}(\\text{Big Model})$\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "> Conclusion:\n",
    "\n",
    "* If the excess variance explained by the inclusion of $x_3, \\dots, x_p$ is large relative to the residual variance left after the inclusion of $x_3, \\dots, x_p$, then we conclude that the inclusion of $x_3, \\dots, x_p$ significantly improves the model fit, i.e., \n",
    "\n",
    "$$\n",
    "\\hat F = {\\frac{\\text{SS}_{Reg}(\\text{Small Model}) - \\text{SS}_{Reg}(\\text{Big Model})}{\\Delta \\text{df}} \\Bigg / {\\frac{\\text{SS}_{Res}(\\text{Big Model})}{\\text{df}_{Res}(\\text{Big Model})}}}\n",
    "$$\n",
    "\n",
    "<br><br><br><br><br>\n",
    "\n",
    "* If $\\hat F$ is $\\Large LARGE$ then including the variables of the big model significantly improves the model fit\n",
    "* If $\\hat F$ is $\\scriptsize small$ then including the variables of the big model does not significantly improve the model fit\n",
    "\n",
    "$$\n",
    "\\hat F \\sim F\\Big(\\Delta \\text{df}, \\ \\ \\ \\text{df}_{Res}(\\text{Big Model})\\Big)\n",
    "$$\n",
    "\n",
    "where $\\Delta \\text{df} = \\text{df}_{Reg}(\\text{Small Model}) - \\text{df}_{Reg}(\\text{Big Model})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78061b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = smf.ols('y ~ 1', data=df).fit()\n",
    "big_model = smf.ols('y ~ 1 + x1 + x2', data=df).fit()\n",
    "\n",
    "# ANOVA\n",
    "sm.stats.anova_lm(small_model, big_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193dde1c",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6713c",
   "metadata": {},
   "source": [
    "### §2.1.3 Generalized Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0276cf6",
   "metadata": {},
   "source": [
    "Suppose we want to test some general hypothesis about the coefficients, e.g.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: 2\\beta_1 - 3\\beta_2  = 1  \\quad \\text{and} 3\\beta_0 + \\beta_1 + 4\\beta_2 = 100 \\\\\n",
    "H_a &: 2\\beta_1 - 3\\beta_2 \\neq 1 \\quad \\text{OR} 3\\beta_0 + \\beta_1 + 4\\beta_2 \\neq 100\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is called a **general linear hypothesis** and can be written in matrix form as:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 2 & -3\\\\\n",
    "3 & 1 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\beta_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "100\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "More generally, suppose we want to test the hypothesis\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: R \\betav = q \\\\\n",
    "H_a &: R \\betav \\neq q\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $R$ is a $c \\times (p+1)$ matrix of constants\n",
    "* $q$ is a $c \\times 1$ vector of constants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eabe1c3",
   "metadata": {},
   "source": [
    "Suppose we want to test some general hypothesis about the coefficients, e.g.,\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: 2\\beta_1 - 3\\beta_2  = 1  \\quad \\text{and} \\quad 3\\beta_0 + \\beta_1 + 4\\beta_2 = 100 \\\\\n",
    "H_a &: 2\\beta_1 - 3\\beta_2 \\neq 1 \\quad \\text{OR} \\quad 3\\beta_0 + \\beta_1 + 4\\beta_2 \\neq 100\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "This is called a **general linear hypothesis** and can be written in matrix form as:\n",
    "\n",
    "$$\n",
    "H_0: \\quad\\quad\n",
    "\\begin{bmatrix}\n",
    "0 & 2 & -3\\\\\n",
    "3 & 1 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\beta_2\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "100\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "More generally, suppose we want to test the hypothesis\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: R \\betav = q \\\\\n",
    "H_a &: R \\betav \\neq q\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where \n",
    "* $R$ is a $q \\times p$ matrix of constants\n",
    "* $q$ is a $q \\times 1$ vector of constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16a6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([\n",
    "    [0, 2, 3],\n",
    "    [3, 1, 4],\n",
    "])\n",
    "q = np.array([1, 100])\n",
    "\n",
    "# use statsmodels to test Rb = q\n",
    "fit.f_test((R, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef4746a",
   "metadata": {},
   "source": [
    "> If \n",
    "> * $R = \\begin{bmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "> \n",
    "> * $q = (0, 0)^\\top$ \n",
    ">\n",
    "> what are we testing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.array([\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "q = np.array([0, 0])\n",
    "\n",
    "fit.f_test((R, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86482af",
   "metadata": {},
   "source": [
    "> If \n",
    "> * $R = I_{p+1}$\n",
    "> * $q = 0_{p+1}$ \n",
    ">\n",
    "> what are we testing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62480095",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.eye(3)\n",
    "q = np.zeros(3)\n",
    "\n",
    "fit.f_test((R, q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f325b4b3",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4bfb91",
   "metadata": {},
   "source": [
    "### Try for this example!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5cfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/MunExp.csv\"\n",
    "df = pd.read_csv(url, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14be02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_xy = pd.DataFrame({'x1': df.revenue, 'x2': df.grants, 'y': df.expend})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727c5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('expend ~ revenue + grants', df)\n",
    "fit = model.fit()\n",
    "fit.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "math189",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

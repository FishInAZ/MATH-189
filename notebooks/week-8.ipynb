{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200e3bab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 8\n",
    "## MATH 189 • Data Analysis & Inference • Wi 2024\n",
    "### Siddharth Vishwanath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8700143e-29e1-4307-9662-02a03e22ef20",
   "metadata": {},
   "source": [
    "% # %load tex-macros\n",
    "<div hidden>\n",
    "\\newcommand{\\require}[1]{}\n",
    "\n",
    "$\\require{begingroup}\\require{newcommand}$\n",
    "$\\long\\def \\forcecommand #1{\\providecommand{#1}{}\\renewcommand{#1}}$\n",
    "$\\forcecommand{\\defeq}{\\stackrel{\\small\\bullet}{=}}$\n",
    "$\\forcecommand{\\ra}{\\rangle}$\n",
    "$\\forcecommand{\\la}{\\langle}$\n",
    "$\\forcecommand{\\pr}{{\\mathbb P}}$\n",
    "$\\forcecommand{\\qr}{{\\mathbb Q}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\av}{{\\boldsymbol{a}}}$\n",
    "$\\forcecommand{\\bv}{{\\boldsymbol{b}}}$\n",
    "$\\forcecommand{\\cv}{{\\boldsymbol{c}}}$\n",
    "$\\forcecommand{\\dv}{{\\boldsymbol{d}}}$\n",
    "$\\forcecommand{\\ev}{{\\boldsymbol{e}}}$\n",
    "$\\forcecommand{\\fv}{{\\boldsymbol{f}}}$\n",
    "$\\forcecommand{\\gv}{{\\boldsymbol{g}}}$\n",
    "$\\forcecommand{\\hv}{{\\boldsymbol{h}}}$\n",
    "$\\forcecommand{\\nv}{{\\boldsymbol{n}}}$\n",
    "$\\forcecommand{\\sv}{{\\boldsymbol{s}}}$\n",
    "$\\forcecommand{\\tv}{{\\boldsymbol{t}}}$\n",
    "$\\forcecommand{\\uv}{{\\boldsymbol{u}}}$\n",
    "$\\forcecommand{\\vv}{{\\boldsymbol{v}}}$\n",
    "$\\forcecommand{\\wv}{{\\boldsymbol{w}}}$\n",
    "$\\forcecommand{\\zerov}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\onev}{{\\mathbf{0}}}$\n",
    "$\\forcecommand{\\phiv}{{\\boldsymbol{\\phi}}}$\n",
    "$\\forcecommand{\\cc}{{\\check{C}}}$\n",
    "$\\forcecommand{\\xv}{{\\boldsymbol{x}}}$\n",
    "$\\forcecommand{\\Xv}{{\\boldsymbol{X}\\!}}$\n",
    "$\\forcecommand{\\yv}{{\\boldsymbol{y}}}$\n",
    "$\\forcecommand{\\Yv}{{\\boldsymbol{Y}}}$\n",
    "$\\forcecommand{\\zv}{{\\boldsymbol{z}}}$\n",
    "$\\forcecommand{\\Zv}{{\\boldsymbol{Z}}}$\n",
    "$\\forcecommand{\\Iv}{{\\boldsymbol{I}}}$\n",
    "$\\forcecommand{\\Jv}{{\\boldsymbol{J}}}$\n",
    "$\\forcecommand{\\Cv}{{\\boldsymbol{C}}}$\n",
    "$\\forcecommand{\\Ev}{{\\boldsymbol{E}}}$\n",
    "$\\forcecommand{\\Fv}{{\\boldsymbol{F}}}$\n",
    "$\\forcecommand{\\Gv}{{\\boldsymbol{G}}}$\n",
    "$\\forcecommand{\\Hv}{{\\boldsymbol{H}}}$\n",
    "$\\forcecommand{\\alphav}{{\\boldsymbol{\\alpha}}}$\n",
    "$\\forcecommand{\\epsilonv}{{\\boldsymbol{\\epsilon}}}$\n",
    "$\\forcecommand{\\betav}{{\\boldsymbol{\\beta}}}$\n",
    "$\\forcecommand{\\deltav}{{\\boldsymbol{\\delta}}}$\n",
    "$\\forcecommand{\\gammav}{{\\boldsymbol{\\gamma}}}$\n",
    "$\\forcecommand{\\etav}{{\\boldsymbol{\\eta}}}$\n",
    "$\\forcecommand{\\piv}{{\\boldsymbol{\\pi}}}$\n",
    "$\\forcecommand{\\thetav}{{\\boldsymbol{\\theta}}}$\n",
    "$\\forcecommand{\\tauv}{{\\boldsymbol{\\tau}}}$\n",
    "$\\forcecommand{\\muv}{{\\boldsymbol{\\mu}}}$\n",
    "$\\forcecommand{\\sd}{\\text{SD}}$\n",
    "$\\forcecommand{\\se}{\\text{SE}}$\n",
    "$\\forcecommand{\\med}{\\text{median}}$\n",
    "$\\forcecommand{\\median}{\\text{median}}$\n",
    "$\\forcecommand{\\Ber}{{\\text{Ber}}}$\n",
    "$\\forcecommand{\\Bin}{{\\text{Bin}}}$\n",
    "$\\forcecommand{\\Geo}{{\\text{Geo}}}$\n",
    "$\\forcecommand{\\Unif}{{\\text{Unif}}}$\n",
    "$\\forcecommand{\\Poi}{{\\text{Poi}}}$\n",
    "$\\forcecommand{\\Exp}{{\\text{Exp}}}$\n",
    "$\\forcecommand{\\Chisq}{{\\chi^2}}$\n",
    "$\\forcecommand{\\N}{\\mathbb{N}}$\n",
    "$\\forcecommand{\\iid}{{\\stackrel{iid}{\\sim}}}$\n",
    "$\\forcecommand{\\px}{p_{X}}$\n",
    "$\\forcecommand{\\fx}{f_{X}}$\n",
    "$\\forcecommand{\\Fx}{F_{X}}$\n",
    "$\\forcecommand{\\py}{p_{Y}}$\n",
    "$\\forcecommand{\\pxy}{p_{X,Y}}$\n",
    "$\\forcecommand{\\po}{{p_0}}$\n",
    "$\\forcecommand{\\pa}{{p_a}}$\n",
    "$\\forcecommand{\\Xbar}{\\overline{X}}$\n",
    "$\\forcecommand{\\Ybar}{\\overline{Y}}$\n",
    "$\\forcecommand{\\Zbar}{\\overline{Z}}$\n",
    "$\\forcecommand{\\nXbar}{n \\cdot \\overline{X}}$\n",
    "$\\forcecommand{\\nYbar}{n \\cdot \\overline{Y}}$\n",
    "$\\forcecommand{\\nZbar}{n \\cdot \\overline{Z}}$\n",
    "$\\forcecommand{\\Xn}{X_1, X_2, \\dots, X_n}$\n",
    "$\\forcecommand{\\Xm}{{X_1, X_2, \\dots, X_m}}$\n",
    "$\\forcecommand{\\Yn}{Y_1, Y_2, \\dots, Y_n}$\n",
    "$\\forcecommand{\\Ym}{{Y_1, Y_2, \\dots, Y_m}}$\n",
    "$\\forcecommand{\\sumXn}{X_1 + X_2 + \\dots + X_n}$\n",
    "$\\forcecommand{\\sumym}{Y_1 + Y_2 + \\dots + Y_m}$\n",
    "$\\forcecommand{\\la}{\\ell_\\alpha}$\n",
    "$\\forcecommand{\\ua}{u_\\alpha}$\n",
    "$\\forcecommand{\\at}{{\\alpha/2}}$\n",
    "$\\forcecommand{\\mux}{\\mu_{X}}$\n",
    "$\\forcecommand{\\muy}{\\mu_{Y}}$\n",
    "$\\forcecommand{\\sx}{\\sigma_{X}}$\n",
    "$\\forcecommand{\\sy}{\\sigma_{Y}}$\n",
    "$\\forcecommand{\\pvalue}{$p$-value}$\n",
    "$\\forcecommand{\\Ho}{H_{0}}$\n",
    "$\\forcecommand{\\Ha}{H_{a}}$\n",
    "$\\forcecommand{\\pvalue}{p\\text{-value}}$\n",
    "$\\forcecommand{\\E}{\\mathbb{E}}$\n",
    "$\\newcommand{\\E}{\\mathbb{E}}$\n",
    "\\vskip-\\parskip\n",
    "\\vskip-\\baselineskip\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96abc1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Agenda\n",
    "---\n",
    "\n",
    "#### Regression With Categorical Response Variable\n",
    "1. Odds and Odds Ratio\n",
    "\n",
    "2. Logistic Regression\n",
    "\n",
    "3. Multinomial Logistic Regression\n",
    "\n",
    "4. Model Diagnostics\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19ea4ab",
   "metadata": {},
   "source": [
    "Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f314af",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Optional \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, fixed\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b62d02c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "### The regression model\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\dots + \\beta_p x_{ip} + \\epsilon_i \\quad \\text{where} \\quad \\epsilon_i \\iid (0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "Equivalently, in matrix notation:\n",
    "\n",
    "$$\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "y_1 \\\\\n",
    "y_2 \\\\\n",
    "\\vdots \\\\\n",
    "y_n\n",
    "\\end{pmatrix}\n",
    "}_{\\yv}\n",
    "= \n",
    "\\underbrace{\n",
    "    \\begin{pmatrix}\n",
    "    1 & x_{11} & x_{12} & \\dots & x_{1p} \\\\\n",
    "    1 & x_{21} & x_{22} & \\dots & x_{2p} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "    1 & x_{n1} & x_{n2} & \\dots & x_{np} \\\\\n",
    "    \\end{pmatrix}\n",
    "}_{\\Xv}\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "\\beta_0 \\\\\n",
    "\\beta_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\beta_p\n",
    "\\end{pmatrix}\n",
    "}_{\\betav}\n",
    "+\n",
    "\\underbrace{\n",
    "\\begin{pmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "\\vdots \\\\\n",
    "\\epsilon_n\n",
    "\\end{pmatrix}\n",
    "}_{\\epsilonv}\n",
    "$$\n",
    "i.e., \n",
    "$$\n",
    "\\yv = \\Xv \\betav + \\epsilonv\n",
    "$$\n",
    "\n",
    "where\n",
    "* $\\Xv$ is called the design matrix / the covariate matrix / the feature matrix\n",
    "* $\\betav$ is the vector of coefficients\n",
    "* $\\epsilonv$ is the vector of errors\n",
    "* $\\yv$ is the vector of responses\n",
    "\n",
    "The assumption that $\\epsilon_i \\iid (0, \\sigma^2)$ is equivalent to the assumption that $\\epsilonv$ follows a **multivariate Normal distribution**, i.e.,\n",
    "$\\epsilonv \\sim N\\Big(\\zerov_d, \\sigma^2 \\Iv_{d \\times d}\\Big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24743798",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51774df",
   "metadata": {},
   "source": [
    "Let's consider the following dataset from a Portuguese bank marketing campaign. \n",
    "\n",
    "> The dataset contains information about the clients and whether they subscribed to a term deposit or not. The goal is to predict whether a client will subscribe to a term deposit or not based on the information provided.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d55f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "bank_marketing = fetch_ucirepo(id=222) \n",
    "df = bank_marketing.data.features\n",
    "df['outcome'] = bank_marketing.data.targets['y'].transform(lambda x: 1 if x == 'yes' else 0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27439d92",
   "metadata": {},
   "source": [
    "Let's clean the data a bit by dropping `NaNs` and get rid of the contact, poutcome, pdays and pdays columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916b1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns contact, poutcome, pdays and pday\n",
    "to_drop = ['contact', 'poutcome', 'pdays', 'pdays']\n",
    "df = df.drop(columns=to_drop)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f3e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2435692",
   "metadata": {},
   "source": [
    "Transform job, marital, education, default, housing, loan, month, day_of_week, to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month', 'day_of_week']\n",
    "\n",
    "for var in categorical_vars:\n",
    "    df[var] = df[var].astype('category')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.education.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ead13",
   "metadata": {},
   "source": [
    "When we use linear regression with a binary response variable, we quickly run into a problem. \n",
    "\n",
    "The linear regression model will give us a predicted value for the response variable for any given value of the predictor variable, but this predicted value is not a probability. The predicted value can take on any value between 0 and 1, but it doesn't necessarily represent the probability of the response variable being a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc5786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('outcome ~ education + marital + default + duration + balance', data=df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccea4fb1",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef2187",
   "metadata": {},
   "source": [
    "The interpretation of the coefficients of the linear regression model are as follows:\n",
    "\n",
    "* $\\beta_0$ is the expected value of $y$ when all the $x$'s are 0.... ?\n",
    "* $\\beta_{job}$ is the expected change of $y$ for a one unit change in job, holding all other variables constant.... ?\n",
    "* $\\vdots$\n",
    "* $\\beta_{\\text{duration}}$ is the expected change of $y$ for a one unit change in the duration of the call, holding all other variables constant.... ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185eeae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0635a14",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62a2bd8",
   "metadata": {},
   "source": [
    "Okay, now suppose the bank calls a different customer who is not in the database. The bank has information about the customer's job, marital status, education... etc. The bank wants to predict whether this customer will subscribe to a term deposit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f29cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_customer = pd.DataFrame({\n",
    "    'education': ['primary'],\n",
    "    'marital': ['married'],\n",
    "    'default': ['no'],\n",
    "    'duration': [5000],\n",
    "    'balance': [0]\n",
    "})\n",
    "\n",
    "model.predict(new_customer)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9795798",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f2f082",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### The need for a new model\n",
    "\n",
    "We need a model that can give us the probability of the response variable being a $1$ for any given value of the predictor variables. \n",
    "\n",
    "\n",
    "That is, we want a model which, when given a set of independent variables $x_1, x_2, \\dots, x_p$, will give us, $p(x_1, x_2, \\dots, x_p)$, the probability that the dependent variable $y$ is a $1$.\n",
    "\n",
    "$$\n",
    "(x_1, x_2, \\dots, x_p) \\mapsto p(x_1, x_2, \\dots, x_p)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "p(x_1, x_2, \\dots, x_p) = \\pr(y = 1 \\mid x_1, x_2, \\dots, x_p)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823bdc33",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065b72eb",
   "metadata": {},
   "source": [
    "### Odds\n",
    "\n",
    "Consider the stock price of a famous GPU manufacturer whose valuation recently hit $2 trillion. \n",
    "\n",
    "\n",
    "Suppose there's a $0.7$ probability that the stock price will go down tomorrow, and a $0.3$ probability that the stock price will go up tomorrow.\n",
    "\n",
    "We have the following basic table:\n",
    "\n",
    "| Outcome | Probability |\n",
    "|---------|-------------|\n",
    "| Up      | 0.3         |\n",
    "| Down    | 0.7         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2567d",
   "metadata": {},
   "source": [
    "The odds of the stock price going up tomorrow is:\n",
    "\n",
    "$$\n",
    "\\frac{\\pr(\\text{Up})}{\\pr(\\text{Down})} = \\frac{0.3}{0.7} = \\frac{3}{7}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3f8203",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4e76f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "In general, given an event $A$, which occurs with probability $\\pr(A)$\n",
    "\n",
    "| Outcome | Probability |\n",
    "|---------|-------------|\n",
    "| $A$     | $\\pr(A)$     |\n",
    "| $A^c$   | $1 - \\pr(A)$ |\n",
    "\n",
    "The odds of $A$ is:\n",
    "\n",
    "$$\n",
    "\\text{odds}(A) = \\frac{\\pr(A)}{\\pr(A^c)} = \\frac{\\pr(A)}{1 - \\pr(A)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13266ac",
   "metadata": {},
   "source": [
    "Notably, because $\\pr(A) \\in (0, 1)$, it follows that \n",
    "\n",
    "$$\n",
    "\\text{odds}(A) \\in (0, \\infty)\\\\ \\\\\n",
    "\\implies \\boxed{\\text{log-odds}(A) \\in (-\\infty, \\infty)}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9e797",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c6f844",
   "metadata": {},
   "source": [
    "### Logistic regression\n",
    "\n",
    "Given the independent variables $x_1, x_2, \\dots, x_p$, consider the event \n",
    "\n",
    "$$\n",
    "A = \\{y = 1 \\mid x_1, x_2, \\dots, x_p \\}.\n",
    "$$\n",
    "\n",
    "The log-odds of $A$ is:\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(\\{ y=1 \\mid x_1, x_2, \\dots, x_p \\}) = \\log\\frac{\\pr(A)}{\\pr(A^c)} = \\log\\Bigg(\\frac{\\pr(y=1 \\mid x_1, x_2, \\dots, x_p)}{\\pr(y=0 \\mid x_1, x_2, \\dots, x_p)}\\Bigg)\n",
    "$$\n",
    "\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "\n",
    "Instead of modeling the probability of the response variable directly \n",
    "\n",
    "$$\n",
    "\\pr(y=1 | x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p \\tag{❌}\n",
    "$$\n",
    "\n",
    "logistic regression models the **log-odds** of the response variable\n",
    "\n",
    "$$\n",
    "\\boxed{\\text{log-odds}(y=1 | x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p} \\tag{✅}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b26ab2",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad06350",
   "metadata": {},
   "source": [
    "> #### Okay, so how do I get the probability? 🙄\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e55a09",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\quad\\quad\\quad\\quad\\text{log-odds}(y=1 | x_1, x_2, \\dots, x_p) &= \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\\\ \\\\\n",
    "\\quad\\quad\\quad\\implies \\text{odds}(y=1 | x_1, x_2, \\dots, x_p) &= \\exp\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)\\\\ \\\\\n",
    "\\quad\\quad \\implies  \\frac{\\pr(y=1 | x_1, x_2, \\dots, x_p)}{\\pr(y=0 | x_1, x_2, \\dots, x_p)} &= \\exp\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)\\\\ \\\\\n",
    "\\implies \\frac{\\pr(y=1 | x_1, x_2, \\dots, x_p)}{1-\\pr(y=1 | x_1, x_2, \\dots, x_p)} &= \\exp\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)\\\\ \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "By solving for $\\pr(y=1 | x_1, x_2, \\dots, x_p)$, we get:\n",
    "\n",
    "$$\n",
    "\\pr(y=1 | x_1, x_2, \\dots, x_p) = \\frac{\\exp\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)}{1 + \\exp\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)}\n",
    "$$\n",
    "\n",
    "\n",
    "By taking $\\sigma(z)$ to be the function given by:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{\\exp(z)}{1 + \\exp(z)}\n",
    "$$\n",
    "\n",
    "we get:\n",
    "\n",
    "$$\n",
    "\\boxed{\\pr(y=1 | x_1, x_2, \\dots, x_p) = \\sigma\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46dfac",
   "metadata": {},
   "source": [
    "The function $\\sigma(z)$ is called the **logistic function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e1f16c",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4577e919",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "* Logistic regression models the odds of the response variable being a $1$ as a linear function of the predictor variables.\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y=1 | x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "* The probability of the response variable being a $1$ is given by the logistic function of the linear combination of the predictor variables.\n",
    "\n",
    "$$\n",
    "\\pr(y=1 | x_1, x_2, \\dots, x_p) = \\sigma\\Big(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\\Big)\n",
    "$$\n",
    "\n",
    "* The function which bridges the gap between the log-odds and the probability is called the **logistic function**, or the **sigmoid function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32014849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the sigmoid function\n",
    "\n",
    "sigma = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "x = np.linspace(-10, 10, 100)\n",
    "plt.plot(x, sigma(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b689fc",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86282af5",
   "metadata": {},
   "source": [
    "\n",
    "### Fitting the logistic regression model\n",
    "\n",
    "\n",
    "> #### 1. Baby steps: continuous covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7826ed",
   "metadata": {},
   "source": [
    "Consider the usual `OLS` model used to fit the linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = smf.ols('outcome ~ duration + balance', data=df).fit()\n",
    "ols_model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6985c",
   "metadata": {},
   "source": [
    "In `statsmodels` you can fit the logistic regression model using the `Logit` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm.Logit?\n",
    "\n",
    "logistic_model = smf.logit('outcome ~ duration + balance', data=df).fit()\n",
    "print(logistic_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd5891",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad87c00",
   "metadata": {},
   "source": [
    "> The first table reveals some interesting information which we'll get back to on Wednesay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b700fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model.summary().tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ddd433",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b307cd",
   "metadata": {},
   "source": [
    "> As guaranteed by construction, the logistic regression model will never give you a value which isn't a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799bc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'duration': [3000],\n",
    "    'balance': [0]\n",
    "})\n",
    "\n",
    "ols_model.predict(new_data)[0], logistic_model.predict(new_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86d7c73",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d94e749",
   "metadata": {},
   "source": [
    "### Interpretation of the coefficients\n",
    "\n",
    "Given the logistic regression model\n",
    "\n",
    "$$\n",
    "\\text{log-odds}(y=1 | x_1, x_2, \\dots, x_p) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p\n",
    "$$\n",
    "\n",
    "the partial derivative of the log-odds with respect to $x_i$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i}\\text{log-odds}(y=1 | x_1, x_2, \\dots, x_p) = \\beta_i\n",
    "$$\n",
    "\n",
    "This means that the coefficient $\\beta_i$ is the expected change in the log-odds of the response variable for an infinitesimal change in $x_i$, holding all other variables constant.\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "This is **not the same** as $\\exp(\\beta_i)$ being the expected change in the odds of the response variable!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f42e9",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81914ae0",
   "metadata": {},
   "source": [
    "#### Odds-Ratio\n",
    "\n",
    "If we want an interpretation on the odds-scale (which is more intuitive), we need to do a little more math.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Given two events $A$ and $B$, the odds-ratio of $A$ to $B$ is:\n",
    "\n",
    "$$\n",
    "\\text{odds-ratio}(A:B) = \\frac{\\text{odds}(A)}{\\text{odds}(B)} = \\frac{\\pr(A)/\\pr(A^c)}{\\pr(B)/\\pr(B^c)} = \\frac{\\pr(A)\\pr(B^c)}{\\pr(A^c)\\pr(B)}\n",
    "$$\n",
    "\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac53b2",
   "metadata": {},
   "source": [
    "Now, consider the following events:\n",
    "\n",
    "* $A = \\{y=1 \\mid x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i\\}$\n",
    "* $B = \\{y=1 \\mid x_1, x_2, \\dots, x_p \\text{ and } x_i = x_i + 1\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a912f2",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f1756",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{odds}(A) &= \\text{odds}(y=1 | x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i)\\\\ \\\\ \n",
    "&= \\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i)\\\\ \\\\ \\\\ \\\\\n",
    "\\text{odds}(B) &= \\text{odds}(y=1 | x_1, x_2, \\dots, x_p  \\text{ and } x_i = x_i + 1)\\\\ \\\\ \n",
    "&= \\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i + \\beta_i)\\\\ \\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7daa1",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ae4db",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{odds-ratio}(B:A) &= \\frac{\\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i + \\beta_i)}{\\exp(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\beta_i x_i)}\\\\ \\\\\n",
    "&= \\exp(\\beta_i)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b5eac",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55657ea",
   "metadata": {},
   "source": [
    "This leads to the following interpretation of the coefficient $\\beta_i$:\n",
    "\n",
    "$$\n",
    "\\exp(\\beta_i) = \\frac{\\text{odds}(y=1 \\mid x_i = x_i + 1)}{\\text{odds}(y=1 \\mid x_i = x_i)}\n",
    "$$\n",
    "\n",
    "i.e., $\\exp(\\beta_i)$ is the **relative change** in odds for a one unit change in $x_i$ holding all other variables constant.\n",
    "\n",
    "* $\\beta_i < 0$ implies that a one unit increase in $x_i$ decreases the odds of the response variable $y=1$.\n",
    "* $\\beta_i > 0$ implies that a one unit increase in $x_i$ increases the odds of the response variable $y=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c19e4",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5947d415",
   "metadata": {},
   "source": [
    "> #### 2. Big steps: continuous and categorical covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = smf.logit('outcome ~ duration + balance + job + marital + default', data=df).fit()\n",
    "\n",
    "logistic_model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800ed97b",
   "metadata": {},
   "source": [
    "Let's interpret the coefficient\n",
    "$$\n",
    "\\beta_{\\text{job: blue-collar}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cca65",
   "metadata": {},
   "source": [
    "remember, the reference category for x=job  is `admin.`\n",
    "\n",
    "The coefficient $\\beta_{\\text{job: blue-collar}} = -0.75$ \n",
    "\n",
    "$$\n",
    "\\frac{\\text{odds}(y=1 \\mid \\text{job = blue collar})}{\\text{odds}(\\mid \\text{job = admin})} = \\exp(-0.75) = 0.47\n",
    "$$ \n",
    "\n",
    "This means that the odds of subscribing to a term deposit for a blue-collar worker is $0.47$ times the odds times the odds of subscribing to a term deposit for an admin worker, holding all other variables constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e6f68",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0479efd8",
   "metadata": {},
   "source": [
    "Your turn: \n",
    "\n",
    "* Interpret the coefficient $\\beta_{\\text{duration}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655952c8",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0ae8b",
   "metadata": {},
   "source": [
    "## §2 Under the hood and model diagnostics\n",
    "\n",
    "\n",
    "In order to \"diagnose\" the model, we need to know what the assumptions are and how to check them. \n",
    "\n",
    "\n",
    "#### Logistic regression assumptions\n",
    "\n",
    "Given data $(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)$, the logistic regression model assumes that: \n",
    "\n",
    "* the response variable $y_i$ is a Bernoulli random variable with parameter $p(x_i)$, i.e., $y | x_1, x_2, \\dots, x_p \\sim \\Ber(p(x_i))$\n",
    "* the function $p^{-1}(x)$ is a linear function of the predictor variables, i.e., $\\sigma^{-1}(p(x)) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42308beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate y | x from bernoulli\n",
    "\n",
    "sigma = lambda x: np.exp(x) / (1 + np.exp(x))\n",
    "p_inv = lambda x1, x2: 3 + 4 * x1 - 2 * x2\n",
    "\n",
    "x1 = np.random.normal(0, 1, 1000)\n",
    "x2 = np.random.normal(0, 1, 1000)\n",
    "\n",
    "p = sigma(p_inv(x1, x2))\n",
    "y = stats.bernoulli(p).rvs(1000)\n",
    "df = pd.DataFrame({'x1': x1, 'x2': x2, 'y': y})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e992c",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac972291",
   "metadata": {},
   "source": [
    "#### The likelihood function\n",
    "\n",
    "Given the data $(x_1, y_1), (x_2, y_2), \\dots, (x_n, y_n)$, the likelihood function is:\n",
    "\n",
    "$$\n",
    "L(\\betav) = \\prod_{i=1}^n p(x_i)^{y_i}(1 - p(x_i))^{1 - y_i}\n",
    "$$\n",
    "\n",
    "The log-likelihood function is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\ell(\\betav) &= \\sum_{i=1}^n y_i \\log(p(x_i)) + (1 - y_i) \\log(1 - p(x_i))\\\\ \\\\\n",
    "&= \\sum_{i=1}^n y_i \\log\\Big(\\frac{p(x_i)}{1 - p(x_i)}\\Big) + \\log(1 - p(x_i))\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "Here\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(x_i) &= \\pr(y_i = 1 | x_i) = \\sigma(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2})\\\\ \\\\\n",
    "\\frac{p(x_i)}{1 - p(x_i)} &= \\text{odds}(y_i=1 | x_i) = \\exp(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2})\\\\ \\\\\n",
    "\\implies \\log\\Big(\\frac{p(x_i)}{1 - p(x_i)}\\Big) &= \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "So\n",
    "$$\n",
    "\\ell(\\beta_0, \\beta_1, \\beta_2) = \\sum_{i=1}^n y_i \\Big(\\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2}\\Big) + \\log(1 - \\sigma(\\beta_0 + \\beta_1 x_{1,i} + \\beta_2 x_{2,i}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b2297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_lik(b, df):\n",
    "    Bx = [b[0] + b[1] * x1 + b[2] * x2 for x1, x2 in zip(df.x1, df.x2)]\n",
    "    p = sigma(Bx)\n",
    "    ll = np.sum((Bx * y) + np.log(1 - sigma(Bx)))\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1232d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(b0 = (-4, 4, 0.5), b1=(-4, 4, 0.5), b2=(-4, 4, 0.5))\n",
    "def ll(b0, b1, b2):\n",
    "    return log_lik([b0, b1, b2], df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5340b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "b0, b1, b2 = minimize(lambda b: -log_lik(b, df), [0, 0, 0]).x\n",
    "print(f' b0: {b0}\\n b1: {b1}\\n b2: {b2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0081ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.logit('y ~ x1 + x2', data=df).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf922f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab93edc4",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b64bf",
   "metadata": {},
   "source": [
    "#### Model diagnostics\n",
    "\n",
    "\n",
    "> ##### Fitted values and residuals\n",
    "\n",
    "The logistic regression model assumes that:\n",
    "\n",
    "$$\n",
    "y \\mid x \\sim Ber(p(x))\n",
    "$$\n",
    "\n",
    "therefore,\n",
    "\n",
    "\n",
    "In `statsmodels` the fitted values are given by:\n",
    "\n",
    "$$\n",
    "\\hat\\beta(x) = \\hat\\beta_0 + \\hat\\beta_1 x_1 + \\hat\\beta_2 x_2 + \\dots + \\hat\\beta_p x_p\n",
    "$$\n",
    "\n",
    "and the **predicted probabilities** are:\n",
    "\n",
    "$$\n",
    "\\hat y = \\hat p(x) = \\sigma(\\hat\\beta(x)) \\quad\\quad \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8792e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = model.fittedvalues\n",
    "\n",
    "b = model.params\n",
    "Bx = b['Intercept'] + b['x1'] * df.x1 + b['x2'] * df.x2\n",
    "\n",
    "np.testing.assert_allclose(fitted, Bx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2873e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "px = model.predict(df)\n",
    "\n",
    "np.testing.assert_allclose(sigma(Bx), px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8689a45c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5010e654",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "E(y|x) = p(x) \\quad\\quad \\text{and}\\quad\\quad Var(y|x) = p(x)(1 - p(x))\n",
    "$$\n",
    "\n",
    "and, the **standardized pearson residuals** are defined as:\n",
    "\n",
    "$$\n",
    "\\hat\\epsilon_i = \\frac{y_i - p(x_i)}{\\sqrt{p(x_i) \\times (1-p(x_i))}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198696c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model.resid_pearson\n",
    "residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d5685",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(residuals)), residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df.x1, residuals)\n",
    "plt.scatter(fitted, residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9e084",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe30f76",
   "metadata": {},
   "source": [
    "> ##### Visualizing model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57816f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df contains x1, x2, and y\n",
    "# make a filled contour plot of x1, x2 with colors for the predicted probabilities\n",
    "x1_grid = np.linspace(-3, 3, 100)\n",
    "x2_grid = np.linspace(-3, 3, 100)\n",
    "\n",
    "X1, X2 = np.meshgrid(x1_grid, x2_grid)\n",
    "\n",
    "probs = model.predict(pd.DataFrame({'x1': X1.ravel(), 'x2': X2.ravel()}))\n",
    "P = p.values.reshape(X1.shape)\n",
    "\n",
    "# plot using matplotlib with colorbar\n",
    "plt.contourf(X1, X2, P, cmap='viridis', levels=np.linspace(0, 1, 20), alpha=0.9)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665f95a8",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf9608",
   "metadata": {},
   "source": [
    "> ##### Confusion matrix\n",
    "\n",
    "The confusion matrix is a table which shows the number of true positives, true negatives, false positives and false negatives.\n",
    "\n",
    "| $\\phantom{1}$ | Predicted 0 | Predicted 1 |\n",
    "|---|---|---|\n",
    "| Actual 0 | True Negative | False Positive |\n",
    "| Actual 1 | False Negative | True Positive |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb102d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = model.pred_table(threshold=0.5)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88824323",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pos = c_matrix[1, 1] / c_matrix[1].sum()\n",
    "true_neg = c_matrix[0, 0] / c_matrix[0].sum()\n",
    "false_pos = c_matrix[0, 1] / c_matrix[0].sum()\n",
    "false_neg = c_matrix[1, 0] / c_matrix[1].sum()\n",
    "print(f' True Positive: {true_pos: .3f}\\n True Negative: {true_neg: .3f}\\n False Positive: {false_pos: .3f}\\n False Negative: {false_neg: .3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250214a2",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ce88ea",
   "metadata": {},
   "source": [
    "> #### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5075ff",
   "metadata": {},
   "source": [
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation of the trade-off between the true positive rate and the false positive rate for every possible cut-off value.\n",
    "\n",
    "The Area Under the Curve (AUC) is a single scalar value that summarizes the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4d17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve\n",
    "fpr, tpr, thresholds = metrics.roc_curve(df.y, model.predict(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = (0.1 - 5e-3 <= thresholds) * (thresholds <= 0.1 + 5e-3)\n",
    "tpr[indx], fpr[indx],  thresholds[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.RocCurveDisplay(fpr=fpr, tpr=tpr).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14abee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_auc_score(df.y, model.predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692501cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbd904f",
   "metadata": {},
   "source": [
    "## §3. Multinomial Logistic Regression\n",
    "\n",
    "Suppose, instead of a binary response variable $y \\in \\{0, 1\\}$ we have a response variable $y \\in \\{1, 2, \\dots, k\\}$ which can take values in $k$ different categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f21474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "iris = fetch_ucirepo(id=53) \n",
    "df = iris.data.features\n",
    "df['y'] = iris.data.targets.astype('category')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ba61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [col.replace(' ', '_') for col in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726777c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.y.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9723e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.ols('y ~ sepal_length + sepal_width + petal_length + petal_width', data=df).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform categorical to numeric\n",
    "df['y_numeric'] = df['y'].cat.codes\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415baac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_model = smf.ols('y_numeric ~ sepal_length + sepal_width + petal_length + petal_width', data=df).fit()\n",
    "ols_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ebd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'sepal_length': [15.1],\n",
    "    'sepal_width': [13.5],\n",
    "    'petal_length': [11.4],\n",
    "    'petal_width': [20.2]\n",
    "})\n",
    "\n",
    "ols_model.predict(new_data)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de1a1d",
   "metadata": {},
   "source": [
    "Fitting an OLS model to categorical data, as with the binary data, leads to inconsistent predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12acdb",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763a703",
   "metadata": {},
   "source": [
    "> #### Where do we go from here?\n",
    "\n",
    "\n",
    "The multinomial logistic regression model is a generalization of the logistic regression model to the case where the response variable can take on more than two values.\n",
    "\n",
    "\n",
    "The multinomial logistic regression model assumes that:\n",
    "\n",
    "$$\n",
    "y \\mid x \\sim \\text{Categorical}(\\pi(x))\n",
    "$$\n",
    "\n",
    "i.e., the response variable $y$ follows a categorical distribution with parameters $\\pi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8014850d",
   "metadata": {},
   "source": [
    "<br></br><br></br>\n",
    "\n",
    "\n",
    "Recall from week-2 that:\n",
    "> > Categorical distribution\n",
    "> \n",
    "> A random variable $X \\sim \\text{Categorical}(\\piv)$ has a categorical distribution with parameters $\\piv = (p_1, p_2, \\dots, p_k)$ if\n",
    "> \n",
    "> $$\n",
    "> \\begin{aligned}\n",
    "> \\pr(X = i) &= p_i \\quad \\quad \\text{for } i = 1, 2, \\dots, k \\\\\n",
    "> \\end{aligned}\n",
    "> $$\n",
    "> \n",
    "> and the parameters satisfy the following conditions:\n",
    "> \n",
    "> $$\n",
    "> \\begin{aligned}\n",
    "> 0 \\le p_i &\\le 1 \\quad \\quad \\text{for } i = 1, 2, \\dots, k \\\\\n",
    "> \\sum_{i=1}^k p_i &= 1\n",
    "> \\end{aligned}\n",
    "> $$\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd01470",
   "metadata": {},
   "source": [
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2af1f",
   "metadata": {},
   "source": [
    "Here we're going to assume that the parameters $\\pi(x)$ are given by:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi(x) &= (\\pi_1(x), \\pi_2(x), \\dots, \\pi_k(x))\\\\ \\\\\n",
    "\\pi_i(x) &= \\pr(y = i | x) \\quad \\quad \\text{for } i = 2, 3, 4 \\dots, k\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "and the first parameter is given by:\n",
    "\n",
    "$$\n",
    "\\pi_1(x) = 1 - \\sum_{i=2}^{k} \\pi_i(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0222ed9d",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "<br><br><br><br>\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff3387",
   "metadata": {},
   "source": [
    "Since all of the $\\pi_i(x)$ are probabilities, we can use the logistic regression trick. But, there's one **key difference**\n",
    "\n",
    "\n",
    "> Logistic regression\n",
    "\n",
    "The odds for logistic regression is\n",
    "$$\n",
    "\\text{odds}(\\{y=1|x\\}) = \\pr(y=1\\mid x)/\\pr(y=0\\mid x)\n",
    "$$\n",
    "\n",
    "> Multinomial logistic regression\n",
    "\n",
    "The odds for multinomial logistic regression is\n",
    "$$\n",
    "\\text{odds}(\\{y=i|x\\}) = \\pr(y=i\\mid x)/\\pr(y=1\\mid x)\n",
    "$$\n",
    "\n",
    "i.e., the odds are always in reference to the **baseline** category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429198af",
   "metadata": {},
   "source": [
    "<br></br><br></br>\n",
    "<br></br><br></br>\n",
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb00c89",
   "metadata": {},
   "source": [
    "With this background:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\log\\Bigg(\\frac{\\pi_i(x)}{\\pi_1(x)}\\Bigg) &= \\beta_{i0} + \\beta_{i1} x_1 + \\beta_{i2} x_2 + \\dots + \\beta_{ip} x_p \\quad \\quad \\text{for } i = 2, 3, 4 \\dots, k\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note the $\\beta_{ip}$ term. This is the key difference between the multinomial logistic regression model and the logistic regression model.\n",
    "\n",
    "\n",
    "> Essentially, the multinomial logistic regression model fits $(k-1)$ different logistic regression models, one for each category, with the first category as the reference category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75e65ab",
   "metadata": {},
   "source": [
    "<br></br><br></br>\n",
    "<br></br><br></br>\n",
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a1450",
   "metadata": {},
   "source": [
    "In `statsmodels` you can fit a multinomial logistic regression model using the `MNLogit` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f5b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model = smf.mnlogit('y_numeric ~ sepal_length + sepal_width + petal_length + petal_width', data=df).fit()\n",
    "print(mnl_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168228cb",
   "metadata": {},
   "source": [
    "> We'll interpret the coefficients on Friday. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a81ab",
   "metadata": {},
   "source": [
    "<br></br><br></br>\n",
    "<br></br><br></br>\n",
    "<br></br><br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774333d4",
   "metadata": {},
   "source": [
    "> #### Marginal Effects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model.summary().tables[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08959e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2051de",
   "metadata": {},
   "source": [
    "> ##### Predicted values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be556069",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac3543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find predicted class\n",
    "predicted_class = mnl_model.predict(df).idxmax(axis=1)\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88daa37",
   "metadata": {},
   "source": [
    "> ##### Confusion Matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a7695",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnl_model.pred_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8f9f2",
   "metadata": {},
   "source": [
    "> ##### TPR, FNR, ROC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "onehot_y = LabelBinarizer().fit(df.y).transform(df.y)\n",
    "onehot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 2\n",
    "metrics.RocCurveDisplay.from_predictions(\n",
    "    onehot_y[:,class_id], \n",
    "    mnl_model.predict(df)[class_id]\n",
    ").plot();"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "math189",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "toc": {
   "base_numbering": 2
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
